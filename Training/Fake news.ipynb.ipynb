{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf56ef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19277dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4ee5e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/HLC/Downloads/FAKE NEWS ANALYSIS/dataset/DATASET.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1d3360a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series to store the labels: y\n",
    "# y = df.label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0757b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned file containing the text and label\n",
    "X = df['text']  # independent variable\n",
    "y = df['label'] #dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b39c98ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.33, random_state=53)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4c4fb831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a CountVectorizer object: count_vectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7fb4f353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training data using only the 'text' column values: count_train\n",
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5d1b9573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test data using only the 'text' column values: count_test\n",
    "count_test = count_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "61541b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '00000031', '000035', '00006', '0001', '0001pt', '000ft', '000km']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Print the first 10 features of the count_vectorizer\n",
    "print(count_vectorizer.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cbcaf22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "58af873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training data: tfidf_train\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b66e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the test data: tfidf_test\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cf93a40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '00000031', '000035', '00006', '0001', '0001pt', '000ft', '000km']\n"
     ]
    }
   ],
   "source": [
    "# Print the first 10 features\n",
    "print(tfidf_vectorizer.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3097d941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Print the first 5 vectors of the tfidf training data\n",
    "print(tfidf_train.A[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5862dc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8b7e1b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create the TfidfVectorizer DataFrame: tfidf_df\n",
    "tfidf_df = pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d34f4497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   00  000  0000  00000031  000035  00006  0001  0001pt  000ft  000km  ...  \\\n",
      "0   0    0     0         0       0      0     0       0      0      0  ...   \n",
      "1   0    0     0         0       0      0     0       0      0      0  ...   \n",
      "2   0    0     0         0       0      0     0       0      0      0  ...   \n",
      "3   0    0     0         0       0      0     0       0      0      0  ...   \n",
      "4   0    0     0         0       0      0     0       0      0      0  ...   \n",
      "\n",
      "   حلب  عربي  عن  لم  ما  محاولات  من  هذا  والمرضى  ยงade  \n",
      "0    0     0   0   0   0        0   0    0        0      0  \n",
      "1    0     0   0   0   0        0   0    0        0      0  \n",
      "2    0     0   0   0   0        0   0    0        0      0  \n",
      "3    0     0   0   0   0        0   0    0        0      0  \n",
      "4    0     0   0   0   0        0   0    0        0      0  \n",
      "\n",
      "[5 rows x 56922 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the head of count_df\n",
    "print(count_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1cccffd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    00  000  0000  00000031  000035  00006  0001  0001pt  000ft  000km  ...  \\\n",
      "0  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
      "1  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
      "2  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
      "3  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
      "4  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n",
      "\n",
      "   حلب  عربي   عن   لم   ما  محاولات   من  هذا  والمرضى  ยงade  \n",
      "0  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
      "1  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
      "2  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
      "3  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
      "4  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n",
      "\n",
      "[5 rows x 56922 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the head of tfidf_df\n",
    "print(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4ef1263b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "# Calculate the difference in columns: difference\n",
    "difference = set(count_df.columns) - set(tfidf_df.columns)\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ccfe82ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Check whether the DataFrame are equal\n",
    "print(count_df.equals(tfidf_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d9114238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "80dd9f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(count_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8ff332a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e8106032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.893352462936394\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy score: score\n",
    "score = accuracy_score(y_test, pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8b2d8e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 865  143]\n",
      " [  80 1003]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix: cm\n",
    "cm =confusion_matrix(y_test, pred, labels=['FAKE', 'REAL'])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "acfdef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and testing the \"fake news\" model with TfidfVectorizer\n",
    "nb_classifier = MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "002ef875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(tfidf_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3988e3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(tfidf_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "56bdd36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8565279770444764\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy score: score\n",
    "score = accuracy_score(y_test, pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cfac8862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 739  269]\n",
      " [  31 1052]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix: cm\n",
    "cm = confusion_matrix(y_test, pred, labels=['FAKE', 'REAL'])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9e9ae956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Improving the model to test a few different alpha levels using the Tfidf vectors,\n",
    "# to determine.if there is a better performing combination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3312543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(0, 1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2c1d7224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train_and_predict()\n",
    "def train_and_predict(alpha):\n",
    "    # Instantiate the classifier: nb_classifier\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "    \n",
    "    # Fit to the training data\n",
    "    nb_classifier.fit(tfidf_train, y_train)\n",
    "    \n",
    "    # Predict the labels: pred\n",
    "    pred = nb_classifier.predict(tfidf_test)\n",
    "    \n",
    "    # Compute accuracy: score\n",
    "    score = accuracy_score(y_test, pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "519d40cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:  0.0\n",
      "Score:  0.8813964610234337\n",
      "\n",
      "Alpha:  0.1\n",
      "Score:  0.8976566236250598\n",
      "\n",
      "Alpha:  0.2\n",
      "Score:  0.8938307030129125\n",
      "\n",
      "Alpha:  0.30000000000000004\n",
      "Score:  0.8900047824007652\n",
      "\n",
      "Alpha:  0.4\n",
      "Score:  0.8857006217120995\n",
      "\n",
      "Alpha:  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:555: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.8842659014825442\n",
      "\n",
      "Alpha:  0.6000000000000001\n",
      "Score:  0.874701099952176\n",
      "\n",
      "Alpha:  0.7000000000000001\n",
      "Score:  0.8703969392635102\n",
      "\n",
      "Alpha:  0.8\n",
      "Score:  0.8660927785748446\n",
      "\n",
      "Alpha:  0.9\n",
      "Score:  0.8589191774270684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the alphas and print the corresponding score\n",
    "for alpha in alphas:\n",
    "    print('Alpha: ', alpha)\n",
    "    print('Score: ', train_and_predict(alpha))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a30ef4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = nb_classifier.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "20ed57d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Extract the features: feature_names\n",
    "feature_names = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "088d6f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Zip the feature names together with the coefficient array \n",
    "# and sort by weights: feat_with_weights\n",
    "feat_with_weights = sorted(zip(nb_classifier.coef_[0], feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2441b5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAKE [(-11.316312804238807, '0000'), (-11.316312804238807, '000035'), (-11.316312804238807, '0001'), (-11.316312804238807, '0001pt'), (-11.316312804238807, '000km'), (-11.316312804238807, '0011'), (-11.316312804238807, '006s'), (-11.316312804238807, '007'), (-11.316312804238807, '007s'), (-11.316312804238807, '008s'), (-11.316312804238807, '0099'), (-11.316312804238807, '00am'), (-11.316312804238807, '00p'), (-11.316312804238807, '00pm'), (-11.316312804238807, '014'), (-11.316312804238807, '015'), (-11.316312804238807, '018'), (-11.316312804238807, '01am'), (-11.316312804238807, '020'), (-11.316312804238807, '023')]\n"
     ]
    }
   ],
   "source": [
    "# Print the first class label and the top 20 feat_with_weights entries\n",
    "print(class_labels[0], feat_with_weights[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d6103ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAL [(-7.742481952533027, 'states'), (-7.717550034444668, 'rubio'), (-7.703583809227384, 'voters'), (-7.654774992495461, 'house'), (-7.649398936153309, 'republicans'), (-7.6246184189367, 'bush'), (-7.616556675728881, 'percent'), (-7.545789237823644, 'people'), (-7.516447881078008, 'new'), (-7.448027933291952, 'party'), (-7.411148410203476, 'cruz'), (-7.410910239085596, 'state'), (-7.35748985914622, 'republican'), (-7.33649923948987, 'campaign'), (-7.2854057032685775, 'president'), (-7.2166878130917755, 'sanders'), (-7.108263114902301, 'obama'), (-6.724771332488041, 'clinton'), (-6.5653954389926845, 'said'), (-6.328486029596207, 'trump')]\n"
     ]
    }
   ],
   "source": [
    "# Print the second class label and the bottom 20 feat_with_weights entries\n",
    "print(class_labels[1], feat_with_weights[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2b42cfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a pipeline that first creates bag of words(after applying stopwords) & then applies Multinomial Naive Bayes model\n",
    "pipeline = Pipeline([('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "                     ('nbmodel', MultinomialNB())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "95ee1ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer(stop_words='english')),\n",
       "                ('nbmodel', MultinomialNB())])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training our data\n",
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ca6c2650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 739  269]\n",
      " [  31 1052]]\n"
     ]
    }
   ],
   "source": [
    "#Predicting the label for the test data\n",
    "pred = pipeline.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ec812183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Serialising the file\n",
    "#pickle.dump(nb_classifier,open('fake_news.pkl','wb'))\n",
    "#Serialising the file\n",
    "with open('model.pkl', 'wb') as handle:\n",
    "    pickle.dump(pipeline, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603eb266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
